{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f9b35d-ed8a-4277-93ab-8d509f479cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import os\n",
    "## 读取json文件\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from FlagEmbedding import FlagReranker\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "\n",
    "## 读取文件\n",
    "model_embedding = SentenceTransformer('../Model/yangjhchs/acge_text_embedding', device='cuda')\n",
    "model_reranker = FlagReranker('../Model/AI-ModelScope/bge-reranker-v2-m3', use_fp16=True)\n",
    "\n",
    "# 转换为一维的NumPy数组\n",
    "def retriever_top(similarity,num_top,text_list):\n",
    "    retrieve_dict = {}\n",
    "    arr = np.array(similarity).flatten()\n",
    "    # 找到排序后的索引\n",
    "    sorted_indices = arr.argsort()\n",
    "    # 因为argsort()返回的是从小到大排序的索引，所以我们需要从末尾开始取\n",
    "    top3_indices = sorted_indices[-num_top:][::-1]  # 反转切片以获得最大的三个索引\n",
    "    # 获取对应的值\n",
    "    top3_values = arr[top3_indices]\n",
    "    # 输出结果\n",
    "    n = 0\n",
    "    for i, v in zip(top3_indices, top3_values):\n",
    "        retrieve_dict[n] = {}\n",
    "        retrieve_dict[n]['Index'] = i\n",
    "        retrieve_dict[n]['score'] = v\n",
    "        retrieve_dict[n]['content'] = text_list[i]\n",
    "        n = n+1\n",
    "    return retrieve_dict\n",
    "\n",
    "def retriever_rerank(reranker,retrieve_dict,question_intense,num_top_rerank):\n",
    "    rerank_list = []\n",
    "    for i in range(len(retrieve_dict)):\n",
    "        rerank_list.append([str(question_intense), retrieve_dict[i]['content']])\n",
    "    scores = reranker.compute_score(rerank_list, normalize=True)\n",
    "    #print(scores) # [0.00027803096387751553, 0.9948403768236574]\n",
    "\n",
    "    rerank_dict = {}\n",
    "    arr = np.array(scores).flatten()\n",
    "    # 找到排序后的索引\n",
    "    sorted_indices = arr.argsort()\n",
    "    # 因为argsort()返回的是从小到大排序的索引，所以我们需要从末尾开始取\n",
    "    top3_indices = sorted_indices[-num_top_rerank:][::-1]  # 反转切片以获得最大的三个索引\n",
    "    # 获取对应的值\n",
    "    top3_values = arr[top3_indices]\n",
    "    # 输出结果\n",
    "    n = 0\n",
    "    for i, v in zip(top3_indices, top3_values):\n",
    "        rerank_dict[n] = {}\n",
    "        rerank_dict[n]['Index'] = i\n",
    "        rerank_dict[n]['score'] = v\n",
    "        rerank_dict[n]['content'] = retrieve_dict[i]['content']\n",
    "        n = n+1\n",
    "    return rerank_dict\n",
    "\n",
    "def retriever(model,reranker, question, Index, text_list, num_top = 10,num_top_rerank = 3):\n",
    "    question_embeddings = model.encode(question, normalize_embeddings=True)\n",
    "    similarity = Index @ question_embeddings.T\n",
    "    retrieve_dict = retriever_top(similarity,num_top,text_list)\n",
    "    rerank_dict = retriever_rerank(reranker,retrieve_dict,question,num_top_rerank)\n",
    "    \n",
    "    return rerank_dict\n",
    "\n",
    "def load_message(input_content,requirements,Hierarchy,rag_content):\n",
    "    if Hierarchy == \"需求声明\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>\\n\\n根据相关文件给出的信息,相关的体系文件里是否有提出与‘{requirements}’对应的公司内部的要求？不需要考虑编号的一致性!请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n<符合性分析>:符合性分析\\n<原文>:原文\"\n",
    "    elif Hierarchy == \"制定流程\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>\\n\\n在上述相关文件中,请就‘是否直接展示了关于{requirements}的完整的管理流程或作业指导书或具体的操作方式?’,进行符合性分析.请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n\\n<符合性分析>:符合性分析\\n\\n<原文>:原文\"\n",
    "    elif Hierarchy == \"形成指定内容\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>\\n\\n在上述相关文件中,是否有直接展示了‘{requirements}’对应的要求的内容? 即该部分实现了上述要求所要求的内容,而不是提出了对应的要求,而是实现了实际的内容.请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n\\n<符合性分析>:符合性分析\\n\\n<原文>:原文\"\n",
    "    elif Hierarchy == \"形成程序文件\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>\\n\\n在上述相关文件中,是否有直接展示了‘{requirements}’对应的二级程序文件? 该二级文件应该非常详细和直接规定了上述要求对应的管理程序的各种细节,而不仅仅是一个要求.请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n\\n<符合性分析>:符合性分析\\n\\n<文件>:文件名称及核心内容\"\n",
    "    elif Hierarchy == \"形成其他文件\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>\\n\\n<参考样式>{rag_content}\\n\\n</参考样式>在上述原文中,是否有直接展示了‘{requirements}’对应的要求的所形成的文件? 我期望的内容如<参考样式>,即该部分实现了上述要求阶段所输出的结果,而不是提出了对应的要求,也不是管理流程,而是实现了实际产出的内容.请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n\\n<符合性分析>:符合性分析\\n\\n<文件>:文件名称及核心内容\"\n",
    "    elif Hierarchy == \"形成记录\":\n",
    "        messages = f\"<相关文件>:{input_content}</相关文件>在上述原文中,是否有直接展示了如何将‘{requirements}’对应的要求的形成记录? 我需要形成记录的内容, 形成记录的方式以及最后记录文件的名称,如有的话再提供已经形成的记录的表格或者表头.请给出结论,符合性分析,和带文件名称的相关原文.输出格式为:<结论>:结论\\n\\n<符合性分析>:符合性分析\\n\\n<记录>:记录表格名称及核心内容\"\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc015815-3fb1-42e7-8368-c00e2373fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_data_rag(QMS_file_name,enhaced_model_name,test_number=0,Skip_repetitive=True):\n",
    "    ## enhaced_model_name should be \"chat_internlm2_5\",\"chat_qwen2_5\"\n",
    "    if test_number != 0:\n",
    "        print(\"开始RAG!\")\n",
    "    elif test_number == 0:\n",
    "        print(\"开始正式RAG!\")\n",
    "        print(\"检测文件是否已RAG!\")\n",
    "        output_file_path = f\"../RAGed_data/output_{QMS_file_name}_{enhaced_model_name}.csv\"\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(\"该文件已RAG!\")\n",
    "            if Skip_repetitive:\n",
    "                print(\"跳过该文件!\")\n",
    "                return None\n",
    "            else:\n",
    "                print(\"重复RAG并覆盖该文件!\")\n",
    "        else:\n",
    "            print(\"当前文件未RAG!开始审核RAG!\")\n",
    "            print(f\"当前QMS为{QMS_file_name},数据增强模型为{enhaced_model_name}!\")\n",
    "\n",
    "    \n",
    "    df_RAG = pd.read_csv(f\"../RAG_data/RAG_content_file_{QMS_file_name}.csv\",encoding=\"utf-8\")\n",
    "    text_list = df_RAG['content']\n",
    "    Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n",
    "    df_requirements = pd.read_csv(f\"../enhanced_data/enhanced_data_{enhaced_model_name}.csv\",encoding=\"utf-8\")\n",
    "    \n",
    "    enhanced_data_rag_list = []\n",
    "\n",
    "    for i in tqdm(range(len(df_requirements))):\n",
    "        Hierarchy = df_requirements['Hierarchy'][i]\n",
    "        rag_content = df_requirements['enhanced_content'][i]\n",
    "        requirements = df_requirements['requirements'][i]\n",
    "    \n",
    "        ## expert\n",
    "        retrieve_dict = retriever(model_embedding, model_reranker, rag_content, Index, text_list, num_top = 10,num_top_rerank = 3)\n",
    "        input_content = \"\"\n",
    "        for key, value in retrieve_dict.items():\n",
    "            input_content = input_content + '\\n\\n' + retrieve_dict[key]['content']\n",
    "        enhanced_data_rag_list.append(input_content.strip())\n",
    "        if test_number > 0:\n",
    "            if i ==test_number-1:\n",
    "                df_requirements = df_requirements.head(len(enhanced_data_rag_list))\n",
    "                df_requirements['enhanced_data_rag_list'] = enhanced_data_rag_list\n",
    "                df_requirements.to_csv(f\"../RAGed_data/test_enhanced_rag_{QMS_file_name}_{enhaced_model_name}.csv\")\n",
    "                print(\"测试结果保存成功!\")\n",
    "                break\n",
    "\n",
    "    if test_number == 0:\n",
    "        df_requirements['enhanced_data_rag_list'] = enhanced_data_rag_list\n",
    "        df_requirements.to_csv(output_file_path)\n",
    "        print(\"审核结果保存成功!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b6b0c6-3c24-47ab-9f10-4acde6f0f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "该文件已RAG!\n",
      "跳过该文件!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为ZD,数据增强模型为chat_qwen2_5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n",
      "100%|██████████| 294/294 [00:21<00:00, 13.49it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为ZD,数据增强模型为chat_ERNIE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:23<00:00, 12.59it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为ZD,数据增强模型为chat_Qwen!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:23<00:00, 12.63it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为BJ,数据增强模型为chat_internlm2_5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:26<00:00, 11.05it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为BJ,数据增强模型为chat_qwen2_5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:22<00:00, 13.33it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为BJ,数据增强模型为chat_ERNIE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:23<00:00, 12.28it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为BJ,数据增强模型为chat_Qwen!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:23<00:00, 12.52it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为MB,数据增强模型为chat_internlm2_5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:27<00:00, 10.85it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为MB,数据增强模型为chat_qwen2_5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:21<00:00, 13.63it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为MB,数据增强模型为chat_ERNIE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:22<00:00, 12.96it/s]\n",
      "/tmp/ipykernel_2868/1638514433.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Index = torch.load(f'../RAG_data/RAG_Index_file_{QMS_file_name}.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n",
      "开始正式RAG!\n",
      "检测文件是否已RAG!\n",
      "当前文件未RAG!开始审核RAG!\n",
      "当前QMS为MB,数据增强模型为chat_Qwen!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [00:23<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "审核结果保存成功!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "QMS_list = [\"ZD\",\"BJ\", \"MB\"]\n",
    "enhanced_model_list = [\"chat_internlm2_5\",\"chat_qwen2_5\",\"chat_ERNIE\",\"chat_Qwen\"]\n",
    "for QMS in QMS_list:\n",
    "    for enhance_model in enhanced_model_list:\n",
    "        enhanced_data_rag(QMS,enhance_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
