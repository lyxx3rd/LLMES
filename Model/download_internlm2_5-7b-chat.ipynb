{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2_5-7b-chat', cache_dir = \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for ./Shanghai_AI_Laboratory/internlm2_5-7b-chat contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/./Shanghai_AI_Laboratory/internlm2_5-7b-chat.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n",
      "The repository for ./Shanghai_AI_Laboratory/internlm2_5-7b-chat contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/./Shanghai_AI_Laboratory/internlm2_5-7b-chat.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5ecc894c914311ad9f4e97fb3b40cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for ./Shanghai_AI_Laboratory/internlm2_5-7b-chat contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/./Shanghai_AI_Laboratory/internlm2_5-7b-chat.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"./Shanghai_AI_Laboratory/internlm2_5-7b-chat\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model is a type of artificial intelligence (AI) model that has been trained on a massive amount of text data, typically billions of words or more. These models are designed to understand and generate human-like text, making them highly versatile and capable of performing a wide range of natural language processing tasks.\n",
      "\n",
      "Large language models are built using deep learning techniques, specifically neural networks, which allow them to learn complex patterns and relationships within the text data. They are trained using a process called transfer learning, where the model is initially trained on a general corpus of text and then fine-tuned on specific tasks or domains.\n",
      "\n",
      "Some of the most well-known large language models include GPT-3, BERT, and T5, developed by companies like OpenAI, Google, and Facebook. These models have been used in a variety of applications, including chatbots, language translation, content generation, and more.\n",
      "\n",
      "Overall, large language models represent a significant advancement in natural language processing and have the potential to revolutionize the way we interact with technology and each other.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
